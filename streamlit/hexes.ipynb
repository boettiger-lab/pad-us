{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70ecae6-ed3d-47ab-8450-f500ab2f0362",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59760595-9aaa-49ee-b825-09c0ffab9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cng.utils import *\n",
    "from cng.h3 import *\n",
    "from ibis import _\n",
    "import os\n",
    "from osgeo import gdal\n",
    "from minio import Minio\n",
    "import streamlit \n",
    "from datetime import timedelta\n",
    "import geopandas as gpd\n",
    "\n",
    "# Get signed URLs to access license-controlled layers\n",
    "key = st.secrets[\"MINIO_KEY\"]\n",
    "secret = st.secrets[\"MINIO_SECRET\"]\n",
    "client = Minio(\"minio.carlboettiger.info\", key, secret)\n",
    "\n",
    "con = ibis.duckdb.connect(extensions = [\"spatial\", \"h3\"])\n",
    "endpoint = os.getenv(\"AWS_S3_ENDPOINT\", \"minio.carlboettiger.info\")\n",
    "duckdb_install_h3()\n",
    "\n",
    "set_secrets(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b086a1a-af23-487b-923d-fca595a19111",
   "metadata": {},
   "source": [
    "#### Converting data to hexes at zoom 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c7474-7ee6-48b0-8242-6d29a28841f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h3_from_geom(con, name, cols, zoom = 8):\n",
    "    \"\"\"\n",
    "    Computes hexes directly from geometry.\n",
    "    \"\"\"\n",
    "    cols = \", \".join(cols) if isinstance(cols, list) else cols\n",
    "    con.raw_sql(f'''\n",
    "    CREATE OR REPLACE TEMP TABLE t2 AS\n",
    "    SELECT {cols},\n",
    "           h3_polygon_wkt_to_cells_string(ST_Force2D(dump.geom), {zoom}) AS h{zoom}\n",
    "    FROM (\n",
    "        SELECT {cols}, UNNEST(ST_Dump(geom)) AS dump\n",
    "        FROM {name}\n",
    "    )\n",
    "    ''')\n",
    "    print('unnesting')\n",
    "    con.sql(f'''\n",
    "        SELECT {cols}, UNNEST(h{zoom}) AS h{zoom},\n",
    "        ST_GeomFromText(h3_cell_to_boundary_wkt(UNNEST(h{zoom}))) AS geom\n",
    "        FROM t2\n",
    "    ''').to_parquet(f\"{name}_h3_z{zoom}.parquet\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a33f5-3647-40bc-9c03-f145c60b95d1",
   "metadata": {},
   "source": [
    "# TPL Conservation Almanac\n",
    "\n",
    "Hexing this data at zoom 8 level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa510b-3434-4ded-88c7-e06844ee503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpl = client.get_presigned_url(\n",
    "    \"GET\",\n",
    "    \"shared-tpl\",\n",
    "    \"tpl.parquet\",\n",
    "    expires=timedelta(hours=2),\n",
    ")\n",
    "\n",
    "cols = ['fid', 'TPL_ID', 'State', 'County', 'Municipality',\n",
    "       'Site_Name', 'Reported_Acres', 'Close_Year', 'Close_Date', 'Owner_Name',\n",
    "       'Owner_Type', 'Manager_Name', 'Manager_Type', 'Purchase_Type',\n",
    "       'EasementHolder_Name', 'EasementHolder_Type', 'Public_Access_Type',\n",
    "       'Purpose_Type', 'Duration_Type', 'Data_Provider', 'Data_Source',\n",
    "       'Source_Date', 'Data_Aggregator', 'Comments', 'Amount', 'Program_ID',\n",
    "       'Program_Name', 'Sponsor_ID', 'Sponsor_Name', 'Sponsor_Type']\n",
    "\n",
    "\n",
    "tpl_table = (con.read_parquet(tpl)\n",
    "             .mutate(geom = _.geom.convert(\"ESRI:102039\", \"EPSG:4326\"))\n",
    "            )\n",
    "\n",
    "con.create_table('tpl', tpl_table, overwrite=True)\n",
    "h3_from_geom(con, 'tpl', cols)\n",
    "\n",
    "client.fput_object(bucket_name = \"shared-tpl\",\n",
    "           object_name = \"tpl_h3_z8.parquet\",\n",
    "           file_path = \"tpl_h3_z8.parquet\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00cfe9-520c-4839-aeed-46a83b11ecce",
   "metadata": {},
   "source": [
    "# Census\n",
    "\n",
    "Getting polygons and FIPS codes from Census state, county, place, and subdivision data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec60670-4abc-4fc4-86ca-88a77ba69d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_url = \"s3://public-census/2024/state/2024_us_state.parquet\"\n",
    "county_url = \"s3://public-census/2024/county/2024_us_county.parquet\"\n",
    "\n",
    "state_file = '2024_us_state_h3_z8.parquet'\n",
    "county_temp_file = '2024_us_county_h3_z8_temp.parquet'\n",
    "county_file = '2024_us_county_h3_z8.parquet'\n",
    "city_file = '2024_us_places_subdivisions_h3_z8.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd589ad-5b03-41de-8936-c20091a937e1",
   "metadata": {},
   "source": [
    "#### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2ed94-740f-49cd-a041-50401b7c7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert shape file to parquet \n",
    "gdf = gpd.read_file('tl_2024_us_state.shp').to_crs('epsg:4326').rename_geometry('geom').rename(columns={\"GEOID\": \"FIPS\", \"STUSPS\":\"state\", \"NAME\":\"name\"})\n",
    "con.create_table('state_wkt', gdf, overwrite=True)\n",
    "\n",
    "# get geom (duckdb turns geodataframes into wkt)\n",
    "con.sql(\"\"\"\n",
    "SELECT * EXCLUDE geom,\n",
    "  ST_GeomFromWKB(geom) AS geom\n",
    "FROM state_wkt\n",
    "\"\"\").to_parquet(state_url)\n",
    "\n",
    "# convert to h3\n",
    "con.read_parquet(state_url, table_name = 'state')\n",
    "cols = ['STATE','name','FIPS']\n",
    "h3_from_geom(con, 'state', cols)\n",
    "\n",
    "# save file \n",
    "client.fput_object(bucket_name = \"public-census\",\n",
    "           file_path = \"state_h3_z8.parquet\",\n",
    "           object_name = f\"2024/state/{state_file}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ea182-ac50-4ee8-a14b-5dcbcb14a044",
   "metadata": {},
   "source": [
    "#### County"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e703812-5369-4bb3-857f-37ed946168e7",
   "metadata": {},
   "source": [
    "#### Cities (places + subdivisions)\n",
    "\n",
    "Note: Some cities are listed in both \"Places\" and \"Subdivisions\", so we will use `distinct()` to avoid duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3d43f-9ab8-4f3e-a981-51c5eca6f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# convert shape to parquet \n",
    "gdf = gpd.read_file('tl_2024_us_county.shp').to_crs('epsg:4326').rename_geometry('geom').drop('NAME',axis =1).rename(columns={\"GEOID\": \"FIPS\", \"NAMELSAD\":\"name\"})[['geom','name','FIPS','STATEFP']]\n",
    "con.create_table('county_wkt', gdf, overwrite=True)\n",
    "\n",
    "# convert to geom (duckdb turns geodataframes into wkt)\n",
    "con.sql(\"\"\"\n",
    "SELECT * EXCLUDE geom,\n",
    "  ST_GeomFromWKB(geom) AS geom\n",
    "FROM county_wkt\n",
    "\"\"\").to_parquet(county_url)\n",
    "\n",
    "# convert to h3\n",
    "con.read_parquet(county_url, table_name = 'county')\n",
    "cols = ['name','FIPS','STATEFP']\n",
    "h3_from_geom(con, 'county', cols)\n",
    "\n",
    "# save file \n",
    "client.fput_object(bucket_name = \"public-census\",\n",
    "           file_path = \"county_h3_z8.parquet\",\n",
    "           object_name = f\"2024/county/{county_temp_file}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7829daf-8333-4e35-83f6-0a2bbcd174fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get state abbeviations \n",
    "county_geo = con.read_parquet(f\"s3://public-census/2024/county/{county_temp_file}\")\n",
    "state_ids = con.read_parquet(state_url).select('name','state','FIPS').rename(state_name = 'name')\n",
    "county_geo.left_join(state_ids, [county_geo.STATEFP == state_ids.FIPS]).drop('FIPS_right','STATEFP').to_parquet(f\"s3://public-census/2024/county/{county_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e9a96-5fcb-409b-812c-b79f7a319eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_pattern = r\"(?i)\\s*(city|town|village|charter|municipality|Borough)\\b\"\n",
    "city_cols = [\"state\",\"county\",\"FIPS\",\"name\"]\n",
    "\n",
    "places_url = \"https://www2.census.gov/geo/docs/reference/codes2020/national_place_by_county2020.txt\"\n",
    "places_fips = (con.read_csv(places_url)\n",
    "               .rename(state = \"STATE\", county = \"COUNTYNAME\", city = \"PLACENAME\")\n",
    "               .mutate(name=_.city.re_replace(match_pattern, \"\").strip())\n",
    "               .mutate(FIPS = _.COUNTYFP + _.STATEFP)\n",
    "               .select(city_cols))\n",
    "\n",
    "subdivisions_url = \"https://www2.census.gov/geo/docs/reference/codes2020/national_cousub2020.txt\"\n",
    "subdivisions_fips = (con.read_csv(subdivisions_url)\n",
    "                     .rename(state = \"STATE\", county = \"COUNTYNAME\", city = \"COUSUBNAME\")\n",
    "                     .mutate(name=_.city.re_replace(match_pattern, \"\").strip())\n",
    "                     .mutate(FIPS = _.COUNTYFP + _.STATEFP)\n",
    "                     .select(city_cols))\n",
    "\n",
    "city_fips = places_fips.union(subdivisions_fips).distinct() #get unique -> some cities are listed in both places and subdivisions\n",
    "city_geo = city_fips.left_join(county_geo, 'FIPS').drop('FIPS_right','name_right') #get h3 from counties \n",
    "\n",
    "city_joined = city_geo.left_join(state_ids, [city_geo.STATEFP == state_ids.FIPS]).drop('FIPS_right','STATEFP','state_right')# get state ids \n",
    "city_joined.to_parquet(f\"s3://public-census/2024/places_subdivisions/{city_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62511665-7859-4997-98d8-ae7c08b64f46",
   "metadata": {},
   "source": [
    "# Landvote\n",
    "\n",
    "We want to join Landvote data with TPL Conservation Almanac, but Landvote doesn't have spatial data.\n",
    "\n",
    "However, we can join Landvote with Census data to get FIPS codes and hexes. \n",
    "- First, need to split up landvote into its 3 jurisdictions: state, county, and municipals\n",
    "- Join states with Census \"states\" to get state FIPS/hex\n",
    "- Join counties with Census \"counties\" to get county FIPS/hex\n",
    "- Join municipals with Census \"places\" and \"subdivisions\" to get county FIPS/hex\n",
    "- Then join all municipal, county, and state data back together!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ba16f-b876-48f0-b1c1-1d2e1b1d3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "landvote_csv = client.get_presigned_url(\n",
    "    \"GET\",\n",
    "    \"shared-tpl\",\n",
    "    \"landvote.csv\",\n",
    "    expires=timedelta(hours=2),\n",
    ")\n",
    "\n",
    "landvote = (con.read_csv(landvote_csv, ignore_errors=True)\n",
    "            .rename(jurisdiction = \"Jurisdiction Type\", state = \"State\")\n",
    "            .mutate(state = _.state.substitute({'Ore':'OR'}))\n",
    "            .mutate(name=_['Jurisdiction Name'].re_replace(match_pattern, \"\").strip())\n",
    "            .mutate(id=ibis.row_number().over()))\n",
    "\n",
    "final_columns = ['id',\n",
    "    'FIPS',\n",
    "    'state',\n",
    "    'state_name',\n",
    "    'county',\n",
    "    'city',\n",
    "    'jurisdiction',\n",
    "    'Date',\n",
    "    'Description',\n",
    "    'Finance Mechanism',\n",
    "    '\"Other\" Comment',\n",
    "    'Purpose',\n",
    "    'Total Funds at Stake',\n",
    "    'Conservation Funds at Stake',\n",
    "    'Total Funds Approved',\n",
    "    'Conservation Funds Approved',\n",
    "    'Pass?',\n",
    "    'Status',\n",
    "    '% Yes',\n",
    "    '% No',\n",
    "    'Notes',\n",
    "    'Voted Acq. Measure',\n",
    "    'geom',\n",
    "    'h8']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89e4e6-1845-4842-baa4-aa6908a1cde1",
   "metadata": {},
   "source": [
    "#### State level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb7c0c-80bb-4d6d-9088-0877e365a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_geo = con.read_parquet(f\"s3://public-census/2024/state/{state_file}\")\n",
    "states = (landvote.filter(_.jurisdiction == \"State\")\n",
    "            .rename(state_name = \"Jurisdiction Name\")\n",
    "            .mutate(county = ibis.literal('None'))\n",
    "            .mutate(county_fips = ibis.literal('None'))\n",
    "            .mutate(city = ibis.literal('None')))\n",
    "\n",
    "landvote_state = (states.left_join(state_geo, [states.name.upper() == state_geo.name.upper()])\n",
    "                   .select(final_columns))\n",
    "\n",
    "#adding state ID and state name from the county/city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202f31a-5868-4e74-951e-23acb49f0bc7",
   "metadata": {},
   "source": [
    "#### County level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a792367-dcab-4869-94b4-6343a3204e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_geo = con.read_parquet(f\"s3://public-census/2024/county/{county_file}\")\n",
    "\n",
    "county_match_pattern = r\"(?i)\\s*(County)\\b\"\n",
    "\n",
    "counties = (landvote.filter(_.jurisdiction == \"County\")\n",
    "            .rename(county = \"Jurisdiction Name\")\n",
    "            .mutate(city = ibis.literal('None'))\n",
    "            .mutate(name=_.name.re_replace(county_match_pattern, \"\").strip()))\n",
    "\n",
    "landvote_county = (counties.left_join(county_geo, [counties.name.upper() == county_geo.name.upper(), \n",
    "                                                    counties.state == county_geo.state])\n",
    "                   .select(final_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca12e06-8d7f-4a50-906c-7dc02e370072",
   "metadata": {},
   "source": [
    "#### Municipal level\n",
    "\n",
    "Because there isn't a 1 to 1 match from municipals to Census data, we need to use both \"Places\" and \"Subdivisons\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81e457-00ba-4b01-86d7-cf46bec04edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_geo = con.read_parquet(f\"s3://public-census/2024/places_subdivisions/{city_file}\")\n",
    "\n",
    "municipals = landvote.filter(_.jurisdiction == \"Municipal\").rename(city = \"Jurisdiction Name\")\n",
    "\n",
    "landvote_city = (municipals.left_join(city_geo, [municipals.name.upper() == city_geo.name.upper(), \n",
    "                                                  municipals.state == city_geo.state])\n",
    "                 .inner_join(state_ids, [municipals.state == state_ids.state])\n",
    "                 .select(final_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d52d97b-ad14-4d04-89a8-79a813f80353",
   "metadata": {},
   "source": [
    "#### Joining all the landvote data with census\n",
    "Note: `landvote_joined` has more rows than `landvote` because some cities span multiple counties. Each additional county creates a new row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d481736-82f3-4be2-b5af-6280be5e9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "landvote_joined = landvote_city.union(landvote_county).union(landvote_state)\n",
    "landvote_joined.to_parquet(\"s3://shared-tpl/landvote_h3_z8.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
